{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torgoPath = r\"C:\\Users\\Salma\\Downloads\\GP\\Torgodata\"\n",
    "UASpeech = r\"D:\\GP\\UASpeech\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataSetFiles(DataSetPath,labels=True):\n",
    "    dataSetAllMainFolders= sorted(os.listdir(DataSetPath)) #[f_audio,f_label,m_audio,m_label]\n",
    "    allDataFilesInDataSetPaths =[DataSetPath + '\\\\' + Folder+'\\\\'+File for Folder in dataSetAllMainFolders for File in sorted(os.listdir(DataSetPath + '\\\\' + Folder)) if re.search('_audio',Folder)] #get all wav files in one list\n",
    "    if labels:\n",
    "        allLabelFilesInDataSetPaths=[DataSetPath + '\\\\' + Folder+'\\\\'+File for Folder in dataSetAllMainFolders         for File in sorted(os.listdir(DataSetPath + '/' + Folder)) if re.search('_label',Folder)] #get all txt files in one list\n",
    "    else:allLabelFilesInDataSetPaths=[]\n",
    "    del(dataSetAllMainFolders)\n",
    "    return allDataFilesInDataSetPaths,allLabelFilesInDataSetPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataFilesInDataSetPaths,allLabelFilesInDataSetPaths=readDataSetFiles(UASpeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7526\n0\nfirst data file ['D:\\\\GP\\\\UASpeech\\\\data\\\\CF02_audio\\\\CF02_0001.wav'] last data file ['D:\\\\GP\\\\UASpeech\\\\data\\\\F02_audio\\\\F02_3701.wav']\nfirst label file [] last label file []\n"
     ]
    }
   ],
   "source": [
    "print(len(allDataFilesInDataSetPaths))\n",
    "print(len(allLabelFilesInDataSetPaths))\n",
    "print('first data file',allDataFilesInDataSetPaths[:1],'last data file',allDataFilesInDataSetPaths[-1:])\n",
    "print('first label file',allLabelFilesInDataSetPaths[:1],'last label file',allLabelFilesInDataSetPaths[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLabelsLinesFromTxt(dataSetPath):\n",
    "    errorReadLabelTxtFile,allLabelFilesInDataSetPaths=[],[]\n",
    "    labelsFiles=[labelFiles for labelFiles in os.listdir(dataSetPath+'\\\\..') if labelFiles.endswith('.txt')] \n",
    "    for labelsFileName in labelsFiles:\n",
    "        try:\n",
    "            with open(dataSetPath+'\\\\..\\\\'+labelsFileName) as labelTxtFile:\n",
    "                allLabelFilesInDataSetPaths=sorted(labelTxtFile.readlines())\n",
    "                allLabelFilesInDataSetPaths=[line.split(':')[-1].strip() for line in allLabelFilesInDataSetPaths]\n",
    "        except:\n",
    "            errorReadLabelTxtFile.append(labelsFileName)\n",
    "    return allLabelFilesInDataSetPaths,errorReadLabelTxtFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLabelFilesInDataSetPaths,errorReadLabelTxtFile=readLabelsLinesFromTxt(UASpeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7526\n0\n"
     ]
    }
   ],
   "source": [
    "print(len(allLabelFilesInDataSetPaths))\n",
    "print(len(errorReadLabelTxtFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exctract Features Using PNCC\n",
    "### you need to install librosa version !pip install librosa==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.core import stft\n",
    "from librosa import filters\n",
    "from librosa import to_mono\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medium_time_power_calculation(power_stft_signal, M=2):\n",
    "    medium_time_power = np.zeros_like(power_stft_signal)\n",
    "    power_stft_signal = np.pad(power_stft_signal, [(M, M), (0, 0)], 'constant')\n",
    "    for i in range(medium_time_power.shape[0]):\n",
    "        medium_time_power[i, :] = sum([1 / float(2 * M + 1) *power_stft_signal[i + k - M, :] for k in range(2 * M + 1)])\n",
    "    return medium_time_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_lawpass_filtering(rectified_signal, lm_a=0.999, lm_b=0.5):\n",
    "    floor_level = np.zeros_like(rectified_signal)\n",
    "    floor_level[0, ] = 0.9 * rectified_signal[0, ]\n",
    "    for m in range(floor_level.shape[0]):\n",
    "        floor_level[m, ] = np.where(rectified_signal[m, ] >=\n",
    "                                    floor_level[m - 1, ],\n",
    "                                    lm_a * floor_level[m - 1, ] +\n",
    "                                    (1 - lm_a) * rectified_signal[m, ],\n",
    "                                    lm_b * floor_level[m - 1, ] +\n",
    "                                    (1 - lm_b) * rectified_signal[m, ])\n",
    "\n",
    "    return floor_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def halfwave_rectification(subtracted_lower_envelope, th=0):\n",
    "    return np.where(subtracted_lower_envelope < th,\n",
    "                    np.zeros_like(subtracted_lower_envelope),\n",
    "                    subtracted_lower_envelope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_masking(rectified_signal, lam_t=0.85, myu_t=0.2):\n",
    "        # rectified_signal[m, l]\n",
    "    temporal_masked_signal = np.zeros_like(rectified_signal)\n",
    "    online_peak_power = np.zeros_like(rectified_signal)\n",
    "    temporal_masked_signal[0, :] = rectified_signal[0, ]\n",
    "    online_peak_power[0, :] = rectified_signal[0, :]\n",
    "    for m in range(1, rectified_signal.shape[0]):\n",
    "        online_peak_power[m, :] = np.maximum(lam_t * online_peak_power[m-1, :],\n",
    "                                             rectified_signal[m, :])\n",
    "        temporal_masked_signal[m, :] = np.where(\n",
    "            rectified_signal[m, :] >= lam_t * online_peak_power[m - 1, :],\n",
    "            rectified_signal[m, :],\n",
    "            myu_t * online_peak_power[m - 1, :])\n",
    "\n",
    "    return temporal_masked_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_excitation_or_non_excitation(temporal_masked_signal,\n",
    "                                        floor_level, lower_envelope,\n",
    "                                        medium_time_power, c=2):\n",
    "    return np.where(medium_time_power >= c * lower_envelope,\n",
    "                    temporal_masked_signal, floor_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_smoothing(final_output, medium_time_power, N=4, L=128):\n",
    "\n",
    "    spectral_weight_smoothing = np.zeros_like(final_output)\n",
    "    for m in range(final_output.shape[0]):\n",
    "        for l in range(final_output.shape[1]):\n",
    "            l_1 = max(l - N, 1)\n",
    "            l_2 = min(l + N, L)\n",
    "            spectral_weight_smoothing[m, l] = (1/float(l_2 - l_1 + 1)) * \\\n",
    "            sum([(final_output[m, l_] / medium_time_power[m, l_])\n",
    "                 for l_ in range(l_1, l_2)])\n",
    "    return spectral_weight_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_frequency_normalization(power_stft_signal,\n",
    "                                 spectral_weight_smoothing):\n",
    "    return power_stft_signal * spectral_weight_smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_power_normalization(transfer_function,\n",
    "                             final_output, lam_myu=0.999, L=80, k=1):\n",
    "    myu = np.zeros(shape=(transfer_function.shape[0]))\n",
    "    myu[0] = 0.0001\n",
    "    normalized_power = np.zeros_like(transfer_function)\n",
    "    for m in range(1, transfer_function.shape[0]):\n",
    "        myu[m] = lam_myu * myu[m - 1] + \\\n",
    "            (1 - lam_myu) / L * \\\n",
    "            sum([transfer_function[m, s] for s in range(0, L - 1)])\n",
    "    normalized_power = k * transfer_function / myu[:, None]\n",
    "\n",
    "    return normalized_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_function_nonlinearity(normalized_power, n=15):\n",
    "    return normalized_power ** float(1 / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pncc(audio_wave, n_fft=512, sr=16000, winlen=0.020, winstep=0.010,\n",
    "         n_mels=128, n_pncc=40, weight_N=4, power=2):\n",
    "\n",
    "    pre_emphasis_signal = scipy.signal.lfilter([1.0, -0.97], 1, audio_wave)\n",
    "    mono_wave = to_mono(pre_emphasis_signal.T)\n",
    "    stft_pre_emphasis_signal = np.abs(stft(mono_wave,\n",
    "                                           n_fft=n_fft,\n",
    "                                           hop_length=int(sr * winstep),\n",
    "                                           win_length=int(sr * winlen),\n",
    "                                           window=np.ones(int(sr * winlen)),\n",
    "                                           center=False)) ** power\n",
    "\n",
    "    mel_filter = np.abs(filters.mel(sr, n_fft=n_fft, n_mels=n_mels)) ** power\n",
    "    power_stft_signal = np.dot(stft_pre_emphasis_signal.T, mel_filter.T)\n",
    "\n",
    "    medium_time_power = medium_time_power_calculation(power_stft_signal)\n",
    "\n",
    "    lower_envelope = asymmetric_lawpass_filtering(\n",
    "        medium_time_power, 0.999, 0.5)\n",
    "\n",
    "    subtracted_lower_envelope = medium_time_power - lower_envelope\n",
    "\n",
    "    rectified_signal = halfwave_rectification(subtracted_lower_envelope)\n",
    "\n",
    "    floor_level = asymmetric_lawpass_filtering(rectified_signal)\n",
    "\n",
    "    temporal_masked_signal = temporal_masking(rectified_signal)\n",
    "\n",
    "    final_output = switch_excitation_or_non_excitation(\n",
    "        temporal_masked_signal, floor_level, lower_envelope,\n",
    "        medium_time_power)\n",
    "\n",
    "    spectral_weight_smoothing = weight_smoothing(\n",
    "        final_output, medium_time_power, L=n_mels)\n",
    "\n",
    "    transfer_function = time_frequency_normalization(\n",
    "        power_stft_signal,\n",
    "        spectral_weight_smoothing)\n",
    "\n",
    "    normalized_power = mean_power_normalization(\n",
    "        transfer_function, final_output, L=n_mels)\n",
    "\n",
    "    power_law_nonlinearity = power_function_nonlinearity(normalized_power)\n",
    "\n",
    "    dct = np.dot(power_law_nonlinearity, filters.dct(\n",
    "        n_pncc, power_law_nonlinearity.shape[1]).T)\n",
    "\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set variables as default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "n_fft=512\n",
    "winlen=0.020\n",
    "winstep=0.010\n",
    "n_mels=128\n",
    "n_pncc=40\n",
    "weight_N=4\n",
    "power=2\n",
    "AUDIO_DURATION = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7526\nD:\\GP\\UASpeech\\data\\CF02_audio\\CF02_0001.wav\n"
     ]
    }
   ],
   "source": [
    "print(len(allDataFilesInDataSetPaths))\n",
    "print(allDataFilesInDataSetPaths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(PnccFeaturesAsNumpyArray[0])\n",
    "#print(len(PnccFeaturesAsNumpyArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PnccFeatureExtraction(allAudioFilesPaths, sampleRate, audioDuration):\n",
    "    allWavesInDataAsNumpyArray, pnccFeaturesNumpyArray,errorFilesInDataset = [],[],[]\n",
    "    for dataFilePath in allAudioFilesPaths:\n",
    "        print(dataFilePath.split('\\\\')[-1])\n",
    "        try:\n",
    "            signal, sampleRate = librosa.load(dataFilePath , sr = sampleRate , duration = audioDuration , res_type='kaiser_fast')#get signals and sampleRate in ane wave (dataFilePath)   \n",
    "            pnccs = np.mean(pncc(signal, n_fft, sampleRate, winlen, winstep,n_mels, n_pncc, weight_N, power),axis=0)\n",
    "  \n",
    "        except:\n",
    "            errorFilesInDataset.append(dataFilePath)\n",
    "            print('there an error occurred in this file' + dataFilePath)\n",
    "        feature = np.array(pnccs).reshape([-1,1]) #get pncc array featture for one wave after reshape it\n",
    "        pnccFeaturesNumpyArray.append(feature) \n",
    "        allWavesInDataAsNumpyArray.append(signal)    \n",
    "    return pnccFeaturesNumpyArray,allWavesInDataAsNumpyArray,errorFilesInDataset        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CF02_0001.wav\n",
      "there an error occurred in this fileD:\\GP\\UASpeech\\data\\CF02_audio\\CF02_0001.wav\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'pnccs' referenced before assignment",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-9493b3dda28f>\u001b[0m in \u001b[0;36mPnccFeatureExtraction\u001b[1;34m(allAudioFilesPaths, sampleRate, audioDuration)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0merrorFilesInDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFilePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'there an error occurred in this file'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdataFilePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpnccs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get pncc array featture for one wave after reshape it\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mpnccFeaturesNumpyArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mallWavesInDataAsNumpyArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'pnccs' referenced before assignment"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pnccFeaturesNumpyArray, allWavesInDataAsNumpyArray, errorFilesInDataset = PnccFeatureExtraction(allDataFilesInDataSetPaths[:], SAMPLE_RATE, AUDIO_DURATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.78475089e+00]\n",
      " [ 6.99593424e-01]\n",
      " [-2.61023081e-01]\n",
      " [-2.78614445e-01]\n",
      " [-3.33414782e-01]\n",
      " [-2.35515399e-01]\n",
      " [-5.92686233e-02]\n",
      " [-6.61384345e-02]\n",
      " [-5.71070842e-02]\n",
      " [ 1.03512546e-01]\n",
      " [-3.18943151e-03]\n",
      " [-1.50290095e-02]\n",
      " [-8.22147816e-03]]\n",
      "9433\n"
     ]
    }
   ],
   "source": [
    "print(pnccFeaturesNumpyArray[0])\n",
    "print(len(pnccFeaturesNumpyArray))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python370jvsc74a57bd0afc262fa681f62a18d832199f49cd4644c53989ada99c308121848eb1c9add3f",
   "display_name": "Python 3.7.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "afc262fa681f62a18d832199f49cd4644c53989ada99c308121848eb1c9add3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}