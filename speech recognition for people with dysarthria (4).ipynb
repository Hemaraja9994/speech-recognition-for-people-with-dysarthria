{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import re "
   ]
  },
  {
   "source": [
    "## Load DataSet Files name"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torgoPath = r\"E:\\tergo dataset\\data and labels\" # DataSet path update it \n",
    "UASpeech = r\"G:\\New folder (2)\\UASpeech\\audio\" # DataSet path update it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataSetFiles(DataSetPath,labels=True):\n",
    "    dataSetAllMainFolders= sorted(os.listdir(DataSetPath)) #[f_audio,f_label,m_audio,m_label]\n",
    "    allDataFilesInDataSetPaths =[DataSetPath + '\\\\' + Folder+'\\\\'+File for Folder in dataSetAllMainFolders for File in sorted(os.listdir(DataSetPath + '\\\\' + Folder)) if re.search('_audio',Folder)] #get all wav files in one list\n",
    "    if labels:\n",
    "        allLabelFilesInDataSetPaths=[DataSetPath + '\\\\' + Folder+'\\\\'+File for Folder in dataSetAllMainFolders for File in sorted(os.listdir(DataSetPath + '/' + Folder)) if re.search('_label',Folder)] #get all txt files in one list\n",
    "    else:allLabelFilesInDataSetPaths=[]\n",
    "    del(dataSetAllMainFolders)\n",
    "    return allDataFilesInDataSetPaths,allLabelFilesInDataSetPaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataFilesInDataSetPaths,allLabelFilesInDataSetPaths=readDataSetFiles(torgoPath) #for Torgo Dataset\n",
    "allDataFilesInDataSetPaths,allLabelFilesInDataSetPaths=readDataSetFiles(UASpeech,labels=False)#for UASpeech Dataset and call readLabelsLinesFromTxt function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(allDataFilesInDataSetPaths))\n",
    "print(len(allLabelFilesInDataSetPaths))\n",
    "print('first data file',allDataFilesInDataSetPaths[:1],'last data file',allDataFilesInDataSetPaths[-1:])\n",
    "print('first label file',allLabelFilesInDataSetPaths[:1],'last label file',allLabelFilesInDataSetPaths[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLabelsLinesFromTxt(labelsFiles):\n",
    "    errorReadLabelTxtFile,allLabelFilesInDataSetPaths=[],[]\n",
    "    for labelsFileName in labelsFiles:\n",
    "        try:\n",
    "            with open(labelsFileName) as labelTxtFile:\n",
    "                allLabelFilesInDataSetPaths=sorted(labelTxtFile.readlines())\n",
    "                allLabelFilesInDataSetPaths=[line.split(':')[-1].strip() for line in allLabelFilesInDataSetPaths]\n",
    "        except:\n",
    "            errorReadLabelTxtFile.append(labelsFileName)\n",
    "    return allLabelFilesInDataSetPaths,errorReadLabelTxtFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "allLabelFilesInDataSetPaths,errorReadLabelTxtFile=readLabelsLinesFromTxt(UASpeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(allLabelFilesInDataSetPaths))\n",
    "print(len(errorReadLabelTxtFile))"
   ]
  },
  {
   "source": [
    "# set variables as default values "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "SAMPLE_RATE = 16000\n",
    "AUDIO_DURATION = 10 # measured in seconds\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Extract signal and mfcc feature form waves"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSignal_mfccFeature(allAudioFilesPaths,sampleRate,audioDuration):\n",
    "    allWavesInDataAsNumpyArray, errorFilesInDataset,mfccFeaturesNumpyArray= [] ,[] ,[] \n",
    "    for dataFilePath in allAudioFilesPaths: # all wave files paths\n",
    "        print(dataFilePath.split('\\\\')[-1])\n",
    "        try:\n",
    "            signal, sampleRate = librosa.load(dataFilePath , sr = sampleRate , duration = audioDuration , res_type='kaiser_fast')#get signals and sampleRate in ane wave (dataFilePath)   \n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=signal, sr=sampleRate, n_mfcc=40).T,axis=0)  #get mfcc array featture for one wave   \n",
    "        except :\n",
    "            errorFilesInDataset.append(dataFilePath) #collect name of file that have error to find it\n",
    "        feature = np.array(mfccs).reshape([-1,1]) #get mfcc array featture for one wave after reshape it\n",
    "        mfccFeaturesNumpyArray.append(feature)  #apeend featture array to get list of all waves feature                       \n",
    "        allWavesInDataAsNumpyArray.append(signal) #apeend signal array to get list of all waves signals\n",
    "    return mfccFeaturesNumpyArray,allWavesInDataAsNumpyArray,errorFilesInDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mfccFeaturesAsNumpyArray,allWavesInDataAsNumpyArray,errorFilesInDataset = extractSignal_mfccFeature(allDataFilesInDataSetPaths,SAMPLE_RATE,AUDIO_DURATION)"
   ]
  },
  {
   "source": [
    "## Extract Text of audio form txt file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTextFromTextFiles(LabelOfDataSetPaths):\n",
    "    allLabelsInDatasetText,errorTextFilePaths=[],[]\n",
    "    for labelFilePath in LabelOfDataSetPaths:  # all txt files\n",
    "        try:\n",
    "            with open(labelFilePath, \"r\") as labelTextFile: # open label file\n",
    "                allLabelsInDatasetText.append(labelTextFile.read().strip()) #get labels text in one list without duple spaces or \\n\n",
    "            print(labelFilePath.split('\\\\')[-1])\n",
    "        except:\n",
    "            errorTextFilePaths.append(labelFilePath)\n",
    "    return allLabelsInDatasetText,errorTextFilePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "allLabelsInDatasetText,errorTextFilePaths=extractTextFromTextFiles(allLabelFilesInDataSetPaths[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allLabelsInDatasetText[:10])\n",
    "print(len(allLabelsInDatasetText),'\\n\\n')\n",
    "print(allWavesInDataAsNumpyArray[0])\n",
    "print(len(allWavesInDataAsNumpyArray),'\\n\\n')\n",
    "print(errorFilesInDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mfccFeaturesAsNumpyArray[0])\n",
    "print(len(mfccFeaturesAsNumpyArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12,4))\n",
    "librosa.display.waveplot(allWavesInDataAsNumpyArray[0], sr = SAMPLE_RATE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = librosa.feature.mfcc(allWavesInDataAsNumpyArray[0], SAMPLE_RATE, n_mfcc=13)\n",
    "# display MFCCs\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(MFCCs, x_axis = 'time')\n",
    "plt.colorbar()\n",
    "plt.title(\"MFCCs\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = librosa.feature.mfcc(allWavesInDataAsNumpyArray[0], SAMPLE_RATE, n_mfcc=13)\n",
    "MFCCs = MFCCs.T\n",
    "print(MFCCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(mfccFeaturesAsNumpyArray)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(allLabelsInDatasetText)\n",
    "classes = list(le.classes_)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y = np_utils.to_categorical(y, num_classes = len(allLabelsInDatasetText))\n",
    "y = np.array(y)  \n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Activation , Flatten , LSTM, Input\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building LSTM model :\n",
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(LSTM(units = 50 ,dropout = 0.05 , recurrent_dropout = 0.2 ,input_shape =(x_train.shape[1:])))\n",
    "model_LSTM.add(Dense(485,activation = 'softmax'))\n",
    "model_LSTM.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM.fit(x_train,y_train,epochs = 100 ,batch_size = 120)\n",
    "score = model_LSTM.evaluate(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "cfc4dac7468c084d307aa08ac9296834a0ec3041907b428597ed5d5794ddbf16"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}