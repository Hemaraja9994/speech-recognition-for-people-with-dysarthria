{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load DataSet Files name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torgoPath = r\"E:\\tergo dataset\\data and labels\" # DataSet path update it \n",
    "UASpeech = r\"F:\\7sabat\\GP\\Dataset\\UASpeech\\audio\" # DataSet path update it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataSetFiles(DataSetPath,labels=True):\n",
    "    dataSetAllMainFolders= sorted(os.listdir(DataSetPath)) #[f_audio,f_label,m_audio,m_label]\n",
    "    allDataFilesInDataSetPaths =[DataSetPath + '\\\\' + Folder+'\\\\'+File for Folder in dataSetAllMainFolders for File in sorted(os.listdir(DataSetPath + '\\\\' + Folder)) if re.search('_audio',Folder)] #get all wav files in one list\n",
    "    if labels:\n",
    "        allLabelFilesInDataSetPaths=[DataSetPath + '\\\\' + Folder+'\\\\'+File for Folder in dataSetAllMainFolders         for File in sorted(os.listdir(DataSetPath + '/' + Folder)) if re.search('_label',Folder)] #get all txt files in one list\n",
    "    else:allLabelFilesInDataSetPaths=[]\n",
    "    del(dataSetAllMainFolders)\n",
    "    return allDataFilesInDataSetPaths,allLabelFilesInDataSetPaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allDataFilesInDataSetPaths,allLabelFilesInDataSetPaths=readDataSetFiles(torgoPath) #for Torgo Dataset\n",
    "allDataFilesInDataSetPaths,allLabelFilesInDataSetPaths=readDataSetFiles(UASpeech,labels=False)#for UASpeech Dataset and call readLabelsLinesFromTxt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(allDataFilesInDataSetPaths))\n",
    "print(len(allLabelFilesInDataSetPaths))\n",
    "print('first data file',allDataFilesInDataSetPaths[:1],'last data file',allDataFilesInDataSetPaths[-1:])\n",
    "print('first label file',allLabelFilesInDataSetPaths[:1],'last label file',allLabelFilesInDataSetPaths[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLabelsLinesFromTxt(dataSetPath):\n",
    "    errorReadLabelTxtFile,allLabelFilesInDataSetPaths=[],[]\n",
    "    labelsFiles=[labelFiles for labelFiles in os.listdir(dataSetPath+'\\\\..') if labelFiles.endswith('.txt')] \n",
    "    for labelsFileName in labelsFiles:\n",
    "        try:\n",
    "            with open(dataSetPath+'\\\\..\\\\'+labelsFileName) as labelTxtFile:\n",
    "                allLabelFilesInDataSetPaths=sorted(labelTxtFile.readlines())\n",
    "                allLabelFilesInDataSetPaths=[line.split(':')[-1].strip() for line in allLabelFilesInDataSetPaths]\n",
    "        except:\n",
    "            errorReadLabelTxtFile.append(labelsFileName)\n",
    "    return allLabelFilesInDataSetPaths,errorReadLabelTxtFiledef readLabelsLinesFromTxt(dataSetPath):\n",
    "    errorReadLabelTxtFile,allLabelFilesInDataSetPaths=[],[]\n",
    "    labelsFiles=[labelFiles for labelFiles in os.listdir(dataSetPath+'\\\\..') if labelFiles.endswith('.txt')] \n",
    "    for labelsFileName in labelsFiles:\n",
    "        try:\n",
    "            with open(dataSetPath+'\\\\..\\\\'+labelsFileName) as labelTxtFile:\n",
    "                allLabelFilesInDataSetPaths=sorted(labelTxtFile.readlines())\n",
    "                allLabelFilesInDataSetPaths=[line.split(':')[-1].strip() for line in allLabelFilesInDataSetPaths]\n",
    "        except:\n",
    "            errorReadLabelTxtFile.append(labelsFileName)\n",
    "    return allLabelFilesInDataSetPaths,errorReadLabelTxtFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLabelFilesInDataSetPaths,errorReadLabelTxtFile=readLabelsLinesFromTxt(UASpeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(allLabelFilesInDataSetPaths))\n",
    "print(len(errorReadLabelTxtFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (allLabelFilesInDataSetPaths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set variables as default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "AUDIO_DURATION = 10 # measured in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extract signal and mfcc feature form waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSignal_mfccFeature(allAudioFilesPaths,sampleRate,audioDuration):\n",
    "    allWavesInDataAsNumpyArray, errorFilesInDataset,mfccFeaturesNumpyArray= [] ,[] ,[] \n",
    "    for dataFilePath in allAudioFilesPaths: # all wave files paths\n",
    "        print(dataFilePath.split('\\\\')[-1])\n",
    "        try:\n",
    "            signal, sampleRate = librosa.load(dataFilePath , sr = sampleRate , duration = audioDuration , res_type='kaiser_fast')#get signals and sampleRate in ane wave (dataFilePath)   \n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=signal, sr=sampleRate, n_mfcc=40).T,axis=0)  #get mfcc array featture for one wave   \n",
    "        except :\n",
    "            errorFilesInDataset.append(dataFilePath) #collect name of file that have error to find it\n",
    "        feature = np.array(mfccs).reshape([-1,1]) #get mfcc array featture for one wave after reshape it\n",
    "        mfccFeaturesNumpyArray.append(feature)  #apeend featture array to get list of all waves feature                       \n",
    "        allWavesInDataAsNumpyArray.append(signal) #apeend signal array to get list of all waves signals\n",
    "    return mfccFeaturesNumpyArray,allWavesInDataAsNumpyArray,errorFilesInDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mfccFeaturesAsNumpyArray,allWavesInDataAsNumpyArray,errorFilesInDataset = extractSignal_mfccFeature(allDataFilesInDataSetPaths[:],SAMPLE_RATE,AUDIO_DURATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extract Text of audio form txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extractTextFromTextFiles(LabelOfDataSetPaths):\n",
    "#     allLabelsInDatasetText,errorTextFilePaths=[],[]\n",
    "#     for labelFilePath in LabelOfDataSetPaths:  # all txt files\n",
    "#         try:\n",
    "#             with open(labelFilePath, \"r\") as labelTextFile: # open label file\n",
    "#                 allLabelsInDatasetText.append(labelTextFile.read().strip()) #get labels text in one list without duple spaces or \\n\n",
    "#             print(labelFilePath.split('\\\\')[-1])\n",
    "#         except:\n",
    "#             errorTextFilePaths.append(labelFilePath)\n",
    "#             print(errorTextFilePaths[:10])\n",
    "#     return allLabelsInDatasetText,errorTextFilePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "allLabelsInDatasetText = allLabelFilesInDataSetPaths[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allLabelsInDatasetText[:10])\n",
    "print(len(allLabelsInDatasetText),'\\n\\n')\n",
    "print(allWavesInDataAsNumpyArray[0])\n",
    "print(len(allWavesInDataAsNumpyArray),'\\n\\n')\n",
    "print(errorFilesInDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mfccFeaturesAsNumpyArray[0])\n",
    "print(len(mfccFeaturesAsNumpyArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12,4))\n",
    "librosa.display.waveplot(allWavesInDataAsNumpyArray[0], sr = SAMPLE_RATE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = librosa.feature.mfcc(allWavesInDataAsNumpyArray[0], SAMPLE_RATE, n_mfcc=13)\n",
    "# display MFCCs\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(MFCCs, x_axis = 'time')\n",
    "plt.colorbar()\n",
    "plt.title(\"MFCCs\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = librosa.feature.mfcc(allWavesInDataAsNumpyArray[0], SAMPLE_RATE, n_mfcc=13)\n",
    "MFCCs = MFCCs.T\n",
    "print(MFCCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(mfccFeaturesAsNumpyArray)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(allLabelsInDatasetText)\n",
    "classes = list(le.classes_)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y = np_utils.to_categorical(y, num_classes = len(allLabelsInDatasetText))\n",
    "y = np.array(y)  \n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense , Dropout , Activation , Flatten , LSTM, Input , Bidirectional , Embedding\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building LSTM model :\n",
    "out_lstm = 100\n",
    "model_LSTM = Sequential()\n",
    "# model_LSTM.add(Embedding(9400,32))\n",
    "model_LSTM.add(LSTM(units = out_lstm ,dropout = 0.05 , recurrent_dropout = 0.2 ,input_shape =(x_train.shape[1:])))\n",
    "model_LSTM.add(Dense(11000,activation = 'softmax'))\n",
    "model_LSTM.add(Dropout(0.25))\n",
    "model_LSTM.add(Dense(10000,activation = 'sigmoid'))\n",
    "model_LSTM.add(Dense(len(allLabelsInDatasetAsText),activation = 'softmax'))\n",
    "model_LSTM.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM.fit(x_train,y_train,epochs = 16 ,batch_size = 32)\n",
    "score = model_LSTM.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
